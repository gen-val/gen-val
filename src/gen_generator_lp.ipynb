{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b43f826e-e1a4-4855-a339-eb6d4a7536ec",
   "metadata": {},
   "source": [
    "### Generate log probs for generator from ../results jsons "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22956ca0-bb7e-40a8-9223-80d6bb15457e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='To', bytes=[84, 111], logprob=-1.7778946, top_logprobs=[]), ChatCompletionTokenLogprob(token=' output', bytes=[32, 111, 117, 116, 112, 117, 116], logprob=-0.050191425, top_logprobs=[]), ChatCompletionTokenLogprob(token=' all', bytes=[32, 97, 108, 108], logprob=-0.0055171386, top_logprobs=[]), ChatCompletionTokenLogprob(token=' files', bytes=[32, 102, 105, 108, 101, 115], logprob=-0.049635276, top_logprobs=[]), ChatCompletionTokenLogprob(token=' in', bytes=[32, 105, 110], logprob=-0.00046105517, top_logprobs=[])])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "load_dotenv(dotenv_path='../.env')\n",
    "client = AzureOpenAI()\n",
    "\n",
    "def get_logprobs(sentence):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4-turbo-2024-04-09\",  # Make sure to use the appropriate model\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"How do I output all files in a directory using Python?\",\n",
    "            },\n",
    "        ],\n",
    "        max_tokens=5,\n",
    "        logprobs=True\n",
    "    )\n",
    "    return response.choices[0].logprobs\n",
    "\n",
    "sentence = \"This is a test sentence.\"\n",
    "logprobs = get_logprobs(sentence)\n",
    "print(logprobs)\n",
    "\n",
    "# completion = client.chat.completions.create(\n",
    "#     model=\"gpt-4-turbo-2024-04-09\",\n",
    "#     messages=[\n",
    "#         {\n",
    "#             \"role\": \"user\",\n",
    "#             \"content\": \"How do I output all files in a directory using Python?\",\n",
    "#         },\n",
    "#     ],\n",
    "#     max_tokens=0,\n",
    "#     logprobs=1\n",
    "# )\n",
    "\n",
    "# completion = client.Completion.create(\n",
    "#     engine=\"gpt-4-0125-preview\",\n",
    "#     prompt=\"You can use the `os` module in Python to list and output all files in a directory. Here's an example:\\n\\n```python\\nimport os\\n\\n# Specify the directory path\\ndirectory_path = '/path/to/directory'\\n\\n# List all files in the directory\\nfiles = os.listdir(directory_path)\\n\\n# Iterate over each file and print its name\\nfor file in files:\\n    print(file)\\n```\\n\\nThis script imports the `os` module, specifies the directory path, lists all files in the directory using `os.listdir()`, and then iterates over the list of files, printing each file name. Make sure to replace `'/path/to/directory'` with the actual path of the directory you want to list files from.\",\n",
    "#     max_tokens=0,\n",
    "#     logprobs=1\n",
    "# )\n",
    "\n",
    "# print(completion.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "845f0c19-ba65-40c1-a630-e0ee5eafc506",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "APIRemovedInV1",
     "evalue": "\n\nYou tried to access openai.Completion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAPIRemovedInV1\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogprobs\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     18\u001b[0m sentence \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis is a test sentence.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 19\u001b[0m logprobs \u001b[38;5;241m=\u001b[39m get_logprobs(sentence)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(logprobs)\n",
      "Cell \u001b[0;32mIn[2], line 10\u001b[0m, in \u001b[0;36mget_logprobs\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_logprobs\u001b[39m(sentence):\n\u001b[0;32m---> 10\u001b[0m     response \u001b[38;5;241m=\u001b[39m openai\u001b[38;5;241m.\u001b[39mCompletion\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m     11\u001b[0m         engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdavinci\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# Adjust the model name if necessary\u001b[39;00m\n\u001b[1;32m     12\u001b[0m         prompt\u001b[38;5;241m=\u001b[39msentence,\n\u001b[1;32m     13\u001b[0m         max_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     14\u001b[0m         logprobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     15\u001b[0m     )\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogprobs\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/openai/lib/_old_api.py:39\u001b[0m, in \u001b[0;36mAPIRemovedInV1Proxy.__call__\u001b[0;34m(self, *_args, **_kwargs)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m_args: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m APIRemovedInV1(symbol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_symbol)\n",
      "\u001b[0;31mAPIRemovedInV1\u001b[0m: \n\nYou tried to access openai.Completion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "# Configure the OpenAI client for Azure\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_base = \"https://princetonplinc.openai.azure.com/\"\n",
    "openai.api_key = \"396a5291f1f44eedbc350b1e33718e69\"\n",
    "openai.api_version = \"2024-04-01-preview\"  # Adjust the API version if necessary\n",
    "\n",
    "def get_logprobs(sentence):\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"davinci\",  # Adjust the model name if necessary\n",
    "        prompt=sentence,\n",
    "        max_tokens=0,\n",
    "        logprobs=1\n",
    "    )\n",
    "    return response['choices'][0]['logprobs']\n",
    "\n",
    "sentence = \"This is a test sentence.\"\n",
    "logprobs = get_logprobs(sentence)\n",
    "print(logprobs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5eddccf-7e01-4191-9757-e275e17695f9",
   "metadata": {},
   "source": [
    "### make spacing across options (both incorrect and correct) more even."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6b4f2b-56d4-4f79-993b-cd63f5af626a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
